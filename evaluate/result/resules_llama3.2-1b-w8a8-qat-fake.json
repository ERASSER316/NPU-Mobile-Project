{
  "model_path": "../model_quantization/llama3.2-1b-w8a8-qat-fake",
  "quant_mode": "none",
  "data_dir": "../datasets/mergedata_preprocessed",
  "model_size_mb_via_save": 2357.227849006653,
  "evaluation_date": "2025-11-22 10:01:53",
  "test": {
    "ppl": 7.17998826647378,
    "avg_loss": 1.971297748862945,
    "loss_std": 0.2159859836101532,
    "loss_min": 1.2656207084655762,
    "loss_max": 2.730156898498535,
    "total_tokens": 1912813,
    "samples_evaluated": 7757
  },
  "throughput": {
    "mean_latency_ms": 347.9322910308838,
    "tokens_per_sec": 23544.810904811497,
    "batch_size": 8,
    "seq_len": 1024,
    "num_runs": 50
  },
  "throughput_compiled": {
    "mean_latency_ms": 317.9820919036865,
    "tokens_per_sec": 25762.4570961099,
    "batch_size": 8,
    "seq_len": 1024,
    "num_runs": 50
  }
}